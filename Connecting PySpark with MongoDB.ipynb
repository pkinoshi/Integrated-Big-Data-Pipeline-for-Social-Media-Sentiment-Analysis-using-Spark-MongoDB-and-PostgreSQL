{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db448af7-aeba-4c32-a711-383c9aca283c",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c02f496a-5be0-4eca-885b-c871042ab4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "#Functions for Preprocessing\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import lower, col, sum, when, regexp_replace, trim\n",
    "from pyspark.sql.types import StringType, LongType, TimestampType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f6e073-75ab-4029-aa53-48a90346548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "171c9505-0324-44ec-8b12-8f6bb6e37962",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MongoDB Integration\") \\\n",
    "    .config(\"spark.jars\", \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\mongo-spark-connector_2.13-10.5.0.jar,\"\n",
    "            \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\mongodb-driver-sync-4.9.0.jar,\"\n",
    "            \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\mongodb-driver-core-4.9.0.jar,\"\n",
    "            \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\bson-4.9.0.jar\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3be3cb1-b137-42b6-9165-b759afd029e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"mongodb\") \\\n",
    "    .option(\"spark.mongodb.read.connection.uri\", \"mongodb://localhost:27017\") \\\n",
    "    .option(\"spark.mongodb.read.database\", \"tweet_db\") \\\n",
    "    .option(\"spark.mongodb.read.collection\", \"tweets\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a3eca4-aea7-4bb0-acf7-323798cacded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- author_id: long (nullable = true)\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90e283ee-a6d5-4c0c-8007-530966926f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "|                 _id|          author_id|          created_at|                 id|                text|\n",
      "+--------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "|6891a2e83a8bc8d49...| 986623019819954176|2025-08-04T13:42:...|1952364494056726579|@eurogamer Hopefu...|\n",
      "|6891a2e83a8bc8d49...|1481237608063979522|2025-08-04T13:42:...|1952364487782334584|@CyberSaintHQ  La...|\n",
      "|6891a2e83a8bc8d49...|          467061296|2025-08-04T13:42:...|1952364485701960138|RT @LeonWohlgemut...|\n",
      "|6891a2e83a8bc8d49...|          257526240|2025-08-04T13:42:...|1952364483138957781|RT @RealPatrickWe...|\n",
      "|6891a2e83a8bc8d49...|1168547410647355392|2025-08-04T13:42:...|1952364481600000265|Iâ€™ve been a DEX u...|\n",
      "+--------------------+-------------------+--------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8411d9a-b468-4294-8681-d76d09bb991b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(spark://DESKTOP-OBIQKOI:52457/jars/mongo-spark-connector_2.13-10.5.0.jar, spark://DESKTOP-OBIQKOI:52457/jars/mongodb-driver-core-4.9.0.jar, spark://DESKTOP-OBIQKOI:52457/jars/mongodb-driver-sync-4.9.0.jar, spark://DESKTOP-OBIQKOI:52457/jars/bson-4.9.0.jar)\n"
     ]
    }
   ],
   "source": [
    "print(spark.sparkContext._jsc.sc().listJars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a78c94-4e53-41bb-be32-961bf7f90e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_id', 'string'),\n",
       " ('author_id', 'bigint'),\n",
       " ('created_at', 'string'),\n",
       " ('id', 'bigint'),\n",
       " ('text', 'string')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f51c1-0f17-45b9-a572-2b2f7c774cdd",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5266c637-9a6c-4c87-a1ae-0fc00415fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a132d30d-1d66-4a33-93da-8ecd9ed01895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ec4128-95b0-4e51-ac46-8062c00da9fd",
   "metadata": {},
   "source": [
    "*__All 80 records are unique__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c6c6194-3c9c-4f10-9c3d-dc63ea625ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+---+----+\n",
      "|_id|author_id|created_at| id|text|\n",
      "+---+---------+----------+---+----+\n",
      "|  0|        0|         0|  0|   0|\n",
      "+---+---------+----------+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_counts = df.select([sum(col(c).isNull().cast(\"int\")).alias(c)\n",
    "                            for c in df.columns])\n",
    "missing_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d769d-24e2-4a5f-8806-d079b3a5a46f",
   "metadata": {},
   "source": [
    "*__There are no missing values in any column__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8264d61d-1adc-48d7-907c-1bd28d11c811",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with irrelevant text\n",
    "df = df.filter(df['text'] != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56f33ac1-44fc-44ef-8e5d-8765e458c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (df.count(), len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fac818ab-59b6-4207-bb22-60b69c192a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a93fba17-bc8b-4b21-b3d8-3f3bd880ed3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Text manipulation using regular expression (regex)\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'http\\S+', ''))  # Remove URLs\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'@\\w+', ''))     # Remove mentions\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'#\\w+', ''))     # Remove hashtags\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'[^a-zA-Z\\s]', ''))  # Remove special characters\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'\\n', ''))\n",
    "df = df.withColumn('text', trim(col('text'))) #Remove leading or trailing white spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "067fb679-b673-464a-9fec-917f4e897fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|OR COULD IT BE TH...|\n",
      "|RT  Elon I worked...|\n",
      "|In the US at leas...|\n",
      "|RT  Disney planne...|\n",
      "|RT  BREAKING Lock...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df.select('text').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87f953e4-5c25-4ad7-a417-c038a8048956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing datatypes\n",
    "df = df.withColumn('author_id', df['author_id'].cast(LongType()))\n",
    "df = df.withColumn('created_at', df['created_at'].cast(TimestampType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "759ab3fd-dbc3-4f7a-bb6d-ab474d5dd3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('_id', 'string'),\n",
       " ('author_id', 'bigint'),\n",
       " ('created_at', 'timestamp'),\n",
       " ('id', 'bigint'),\n",
       " ('text', 'string')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dfac14-bc03-4a3f-89c7-03978298f80b",
   "metadata": {},
   "source": [
    "__*Long and bigint are similar*__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512fcd5-dc55-42bf-97ef-7b123d88a601",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a76b70b-3f21-4cc2-9e52-a58e7ce1739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "df_clean = df.withColumn('text', lower(col('text')))\n",
    "df_clean = df_clean.withColumn('text', col('text').cast(\"string\"))\n",
    "\n",
    "# Sentiment word lists\n",
    "positive_words = [\"good\", \"great\", \"excellent\", \"happy\", \"love\", \"amazing\", \"awesome\"]\n",
    "negative_words = [\"bad\", \"terrible\", \"sad\", \"hate\", \"poor\", \"awful\", \"worst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16befa9a-9e39-403f-9aa3-0ad94779ab2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "|                 _id|          author_id|         created_at|                 id|                text|\n",
      "+--------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "|6891a2e83a8bc8d49...|1373906096792989696|2025-08-04 14:42:03|1952364410074234928|or could it be th...|\n",
      "|6891a2e83a8bc8d49...|1756438119287566336|2025-08-04 14:41:53|1952364370069217638|rt  elon i worked...|\n",
      "|6891a2e83a8bc8d49...|1154966639408013312|2025-08-04 14:42:06|1952364425240826229|in the us at leas...|\n",
      "|6891a2e83a8bc8d49...|         3389907262|2025-08-04 14:42:20|1952364480869826560|rt  disney planne...|\n",
      "|6891a2e83a8bc8d49...|1331232643330023429|2025-08-04 14:42:04|1952364414289764415|rt  breaking lock...|\n",
      "+--------------------+-------------------+-------------------+-------------------+--------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_clean.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9b3d9be8-1a6d-4002-9f78-52c03a0a4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_condition = reduce(lambda a, b: a | b, [col(\"text\").contains(word) for word in positive_words])\n",
    "negative_condition = reduce(lambda a, b: a | b, [col(\"text\").contains(word) for word in negative_words])\n",
    "\n",
    "df_with_sentiment = df_clean.withColumn(\n",
    "    \"sentiment\",\n",
    "    when(positive_condition, \"positive\")\n",
    "    .when(negative_condition, \"negative\")\n",
    "    .otherwise(\"neutral\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c815650d-460c-45ed-82d8-a7e93b074096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+--------------------+---------+\n",
      "|                 _id|          author_id|         created_at|                 id|                text|sentiment|\n",
      "+--------------------+-------------------+-------------------+-------------------+--------------------+---------+\n",
      "|6891a2e83a8bc8d49...|1373906096792989696|2025-08-04 14:42:03|1952364410074234928|or could it be th...|  neutral|\n",
      "|6891a2e83a8bc8d49...|1756438119287566336|2025-08-04 14:41:53|1952364370069217638|rt  elon i worked...|  neutral|\n",
      "|6891a2e83a8bc8d49...|1154966639408013312|2025-08-04 14:42:06|1952364425240826229|in the us at leas...|  neutral|\n",
      "|6891a2e83a8bc8d49...|         3389907262|2025-08-04 14:42:20|1952364480869826560|rt  disney planne...|  neutral|\n",
      "|6891a2e83a8bc8d49...|1331232643330023429|2025-08-04 14:42:04|1952364414289764415|rt  breaking lock...|  neutral|\n",
      "|6891a2e83a8bc8d49...|          453639280|2025-08-04 14:41:59|1952364394152686018|whats with the br...|  neutral|\n",
      "|6891a2e83a8bc8d49...|1168547410647355392|2025-08-04 14:42:20|1952364481600000265|ive been a dex us...| positive|\n",
      "|6891a2e83a8bc8d49...|           24572509|2025-08-04 14:42:09|1952364438201258436|well see come thi...|  neutral|\n",
      "|6891a2e83a8bc8d49...|          257526240|2025-08-04 14:42:20|1952364483138957781|rt  breaking lock...|  neutral|\n",
      "|6891a2e83a8bc8d49...|1377416459194757120|2025-08-04 14:41:41|1952364318827397428|rt   dear the emp...|  neutral|\n",
      "+--------------------+-------------------+-------------------+-------------------+--------------------+---------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "df_with_sentiment.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d944c06-89c0-4e57-8e50-9dbec5f34b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_sentiment.filter(col(\"text\").like(f\"%technology%\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e2d00cf-d0fd-4340-874c-415be5d03dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_sentiment.filter(col(\"text\").like(f\"%climate%\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7fc498f-7e88-4893-ab5e-3f2d71f39301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_sentiment.filter(col(\"sentiment\").like(f\"%neutral%\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aace4502-0e3e-4c78-bc55-30a7a581e283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_sentiment.filter(col(\"sentiment\").like(f\"%positive%\")).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "79246d48-e5a9-4eb1-a3c4-d34e2a4cf136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_sentiment.filter(col(\"sentiment\").like(f\"%negative%\")).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22b5c21-1d13-4930-b472-cd02f5f42025",
   "metadata": {},
   "source": [
    "### Feature engineering continued - Using NLTK'S opinion lexicon for positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ddefd1c-0ace-41e9-bfc0-f7f926f942b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_opinion_lexicon(path):\n",
    "    with open(path, 'r', encoding='latin-1') as f:\n",
    "        return [line.strip() for line in f if line.strip() and not line.startswith(';')]\n",
    "\n",
    "positive_words2 = load_opinion_lexicon(\"C:\\\\Users\\\\ADURA\\\\Documents\\\\GitHub\\\\nltk\\\\nltk\\\\corpus\\\\positive-words.txt\")\n",
    "negative_words2 = load_opinion_lexicon(\"C:\\\\Users\\\\ADURA\\\\Documents\\\\GitHub\\\\nltk\\\\nltk\\\\corpus\\\\negative-words.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e8c3fcd-6589-4400-a414-a9af1aade209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'accessable',\n",
       " 'accessible',\n",
       " 'acclaim',\n",
       " 'acclaimed',\n",
       " 'acclamation']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_words2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5db2544a-ba5c-4adf-a158-093248920e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(positive_words2), type(negative_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fb9d872b-84ba-4c8d-9640-abaff68d8336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2-faced',\n",
       " '2-faces',\n",
       " 'abnormal',\n",
       " 'abolish',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abort',\n",
       " 'aborted']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_words2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38f8429f-455d-4f34-b76a-e2be0ba290f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_condition2 = reduce(lambda a, b: a | b, [col(\"text\").contains(word) for word in positive_words2])\n",
    "negative_condition2 = reduce(lambda a, b: a | b, [col(\"text\").contains(word) for word in negative_words2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "06d0bb74-5035-44c5-9810-0293b461835e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o156.withColumn.\n: java.lang.StackOverflowError\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_with_sentiment2 \u001b[38;5;241m=\u001b[39m df_clean\u001b[38;5;241m.\u001b[39mwithColumn(\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      3\u001b[0m     when(positive_condition2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mwhen(negative_condition2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39motherwise(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneutral\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\classic\\dataframe.py:1623\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[1;34m(self, colName, col)\u001b[0m\n\u001b[0;32m   1618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[0;32m   1619\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[0;32m   1620\u001b[0m         errorClass\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_COLUMN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1621\u001b[0m         messageParameters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(col)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m},\n\u001b[0;32m   1622\u001b[0m     )\n\u001b[1;32m-> 1623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mwithColumn(colName, col\u001b[38;5;241m.\u001b[39m_jc), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1362\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1356\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1358\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1359\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1361\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1362\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1363\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1365\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:282\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpy4j\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprotocol\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Py4JJavaError\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    284\u001b[0m     converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\protocol.py:327\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    325\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o156.withColumn.\n: java.lang.StackOverflowError\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:86)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$1(columnNodeSupport.scala:48)\r\n\tat org.apache.spark.sql.internal.SQLConf$.withExistingConf(SQLConf.scala:161)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply(columnNodeSupport.scala:47)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.apply$(columnNodeSupport.scala:46)\r\n\tat org.apache.spark.sql.classic.SparkSession$$anon$3.apply(SparkSession.scala:713)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$4(columnNodeSupport.scala:86)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:75)\r\n\tat scala.collection.immutable.ArraySeq.map(ArraySeq.scala:35)\r\n\tat org.apache.spark.sql.classic.ColumnNodeToExpressionConverter.$anonfun$apply$2(columnNodeSupport.scala:86)\r\n"
     ]
    }
   ],
   "source": [
    "df_with_sentiment2 = df_clean.withColumn(\n",
    "    \"sentiment\",\n",
    "    when(positive_condition2, \"positive\")\n",
    "    .when(negative_condition2, \"negative\")\n",
    "    .otherwise(\"neutral\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11b52a-9790-4cdb-8868-38f863915d49",
   "metadata": {},
   "source": [
    "#### TRYING IT IN CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "312477cb-6b41-4440-a121-1b35750f049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_conditions(words, chunk_size=100):\n",
    "    chunks = [words[i:i+chunk_size] for i in range(0, len(words), chunk_size)]\n",
    "    conditions = [reduce(lambda a, b: a | b, [col(\"text\").contains(word) for word in chunk]) for chunk in chunks]\n",
    "    return reduce(lambda a, b: a | b, conditions)\n",
    "\n",
    "positive_condition2 = chunk_conditions(positive_words2)\n",
    "negative_condition2 = chunk_conditions(negative_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "af227407-9619-461c-979e-96ac0a72c769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sentiment2 = df_clean.withColumn(\n",
    "    \"sentiment\",\n",
    "    when(positive_condition2, \"positive\")\n",
    "    .when(negative_condition2, \"negative\")\n",
    "    .otherwise(\"neutral\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a0ff9653-a7fd-482e-97ce-03790b8e24db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-------------------+-------------------+--------------------+---------+\n",
      "|                 _id|          author_id|         created_at|                 id|                text|sentiment|\n",
      "+--------------------+-------------------+-------------------+-------------------+--------------------+---------+\n",
      "|6891a2e83a8bc8d49...|1373906096792989696|2025-08-04 14:42:03|1952364410074234928|or could it be th...| positive|\n",
      "|6891a2e83a8bc8d49...|1756438119287566336|2025-08-04 14:41:53|1952364370069217638|rt  elon i worked...| positive|\n",
      "|6891a2e83a8bc8d49...|1154966639408013312|2025-08-04 14:42:06|1952364425240826229|in the us at leas...| negative|\n",
      "|6891a2e83a8bc8d49...|         3389907262|2025-08-04 14:42:20|1952364480869826560|rt  disney planne...| negative|\n",
      "|6891a2e83a8bc8d49...|1331232643330023429|2025-08-04 14:42:04|1952364414289764415|rt  breaking lock...| positive|\n",
      "+--------------------+-------------------+-------------------+-------------------+--------------------+---------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "df_with_sentiment2.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b516d04d-0abf-4469-8c04-8b58b522a148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- author_id: long (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_with_sentiment2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854135be-fb9f-4772-87fe-c48e7c32b0df",
   "metadata": {},
   "source": [
    "### Exporting df_with_sentiment2 to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "25396125-5419-4e78-86eb-2cff6947472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkb = SparkSession.builder \\\n",
    "    .appName(\"PostgreSQL Integration\") \\\n",
    "    .config(\"spark.jars\", \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\postgresql-42.5.2.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#Testing connection by loading\n",
    "df = sparkb.read.format(\"jdbc\") \\\n",
    "    .option(\"url\", \"jdbc:postgresql://localhost:5432/tweet_sentiments\") \\\n",
    "    .option(\"dbtable\", \"tweets\") \\\n",
    "    .option(\"user\", \"postgres\") \\\n",
    "    .option(\"password\", \"*556#\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2abad7e9-f74d-4277-80c3-88c2fd94b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _id: string (nullable = true)\n",
      " |-- author_id: long (nullable = true)\n",
      " |-- created_at: timestamp (nullable = true)\n",
      " |-- id: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b7a6d78-83d1-47c6-a721-6a48a38bfc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+----------+---+----+---------+\n",
      "|_id|author_id|created_at| id|text|sentiment|\n",
      "+---+---------+----------+---+----+---------+\n",
      "+---+---------+----------+---+----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9abad012-80bb-44ea-a1ab-0b80cfcb3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_sentiment2.write \\\n",
    "  .format(\"jdbc\") \\\n",
    "  .option(\"url\", \"jdbc:postgresql://localhost:5432/tweet_sentiments\") \\\n",
    "  .option(\"dbtable\", \"tweets\") \\\n",
    "  .option(\"user\", \"postgres\") \\\n",
    "  .option(\"password\", \"*556#\") \\\n",
    "  .mode(\"append\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880e63b-2c04-4d0f-853e-1af5305a2d84",
   "metadata": {},
   "source": [
    "### End Spark Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b01cf279-3a73-4abf-9d79-07531cc5accb",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eec90f2e-1ee2-4a8e-a90e-2806489e26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkb.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6e3e8b-9fea-49ca-bfff-9cc463823169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "#Functions for Preprocessing\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import lower, col, sum, when, regexp_replace, trim\n",
    "from pyspark.sql.types import StringType, LongType, TimestampType\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MongoDB Integration\") \\\n",
    "    .config(\"spark.jars\", \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\mongo-spark-connector_2.13-10.5.0.jar,\"\n",
    "            \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\mongodb-driver-sync-4.9.0.jar,\"\n",
    "            \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\mongodb-driver-core-4.9.0.jar,\"\n",
    "            \"C:\\\\Users\\\\ADURA\\\\Documents\\\\spark_jars\\\\bson-4.9.0.jar\").getOrCreate()\n",
    "\n",
    "df = spark.read.format(\"mongodb\") \\\n",
    "    .option(\"spark.mongodb.read.connection.uri\", \"mongodb://localhost:27017\") \\\n",
    "    .option(\"spark.mongodb.read.database\", \"tweet_db\") \\\n",
    "    .option(\"spark.mongodb.read.collection\", \"tweets\") \\\n",
    "    .load()\n",
    "\n",
    "#Text manipulation using regular expression (regex)\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'http\\S+', ''))  # Remove URLs\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'@\\w+', ''))     # Remove mentions\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'#\\w+', ''))     # Remove hashtags\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'[^a-zA-Z\\s]', ''))  # Remove special characters\n",
    "df = df.withColumn('text', regexp_replace(col('text'), r'\\n', ''))\n",
    "df = df.withColumn('text', trim(col('text'))) #Remove leading or trailing white spaces"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
